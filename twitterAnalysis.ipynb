{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataSet = []\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"tweetDataFile.csv\", encoding = 'ISO-8859-1')\n",
    "df.to_csv(\"tweetFile.csv\", header = ['id','text','label','topics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweetFile.csv\", encoding = 'ISO-8859-1')\n",
    "df = shuffle(df)\n",
    "df.reset_index(inplace = True)\n",
    "df.head()\n",
    "df.drop(['index'], inplace = True, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>irrelevant</th>\n",
       "      <td>558</td>\n",
       "      <td>558</td>\n",
       "      <td>558</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1414</td>\n",
       "      <td>1414</td>\n",
       "      <td>1414</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>359</td>\n",
       "      <td>359</td>\n",
       "      <td>359</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0    id  text  topics\n",
       "label                                     \n",
       "irrelevant         558   558   558     558\n",
       "negative           389   389   389     389\n",
       "neutral           1414  1414  1414    1414\n",
       "positive           359   359   359     359"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2722, 5)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    RT @centroandroid: #Google presenta #Android B...\n",
       "1    Android ice-cream sandwich's \"Face Unlock\" fai...\n",
       "2    @eboyee S tim da http://t.co/hX21e1JK daje Ser...\n",
       "3    @Apple would do better to inform customers pro...\n",
       "4    RT @ralphbin: #Microsoft Research shows #Holod...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df['text']\n",
    "y_train = df['label']\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.loc[1129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "X_train = X_train.apply(lambda x : x.lower())\n",
    "X_train = X_train.apply(lambda x : re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '', x))\n",
    "X_train = X_train.apply(lambda x : re.sub('@[^\\s]+', '', x))\n",
    "X_train = X_train.apply(lambda x : x.replace('[^\\w\\s]',' '))\n",
    "X_train = X_train.apply(lambda x :re.sub(r'#([^\\s]+)', r'\\1', x))\n",
    "X_train = X_train.apply(lambda x : re.sub('[^A-Za-z0-9 ]', '', x))\n",
    "\n",
    "# y_train = y_train.apply(lambda x : x.replace(' ','', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text as ext\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#initializing the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        #append the stemmed item to list and return it\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = stem_tokens(tokens)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Ogbuti\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "vect = ext.CountVectorizer(tokenizer = tokenize, stop_words = 'english', min_df = 5).fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2722, 902)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train = vect.transform(X_train)\n",
    "text_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: label, dtype: int64)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = {'positive':0,'negative':1,'neutral':2,'irrelevant':2,}\n",
    "y_train.fillna('irrelevant',inplace = True)\n",
    "y_train = y_train.map(y)\n",
    "y_train[y_train.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    1\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(text_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 2 2 2]\n",
      "[2 1 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(text_train))\n",
    "print(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70       359\n",
      "           1       0.60      0.79      0.68       389\n",
      "           2       0.91      0.86      0.89      1974\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      2722\n",
      "   macro avg       0.74      0.78      0.76      2722\n",
      "weighted avg       0.84      0.83      0.83      2722\n",
      "\n",
      "Accuracy:  0.8277002204261572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "pred = classifier.predict(text_train)\n",
    "print(classification_report(y_train, pred))\n",
    "print('Accuracy: ', accuracy_score(y_train,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
